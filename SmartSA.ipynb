{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyORy2hbFZXyqCE6umcOE/md",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nakhimchea/sentiment_analysis_ipynb/blob/main/SmartSA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Import Libraries*"
      ],
      "metadata": {
        "id": "sLJi7Uq73aXi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SmartSA: Analysis of Tweeter and Apply to Strategy**"
      ],
      "metadata": {
        "id": "es668-bQ4eWU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tr6WFzvm2Vsa"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from scipy.special import softmax\n",
        "\n",
        "import pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Twitter Scraping**"
      ],
      "metadata": {
        "id": "96Le8_eM3L_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import snscrape.modules.twitter as twitter"
      ],
      "metadata": {
        "id": "cgMln_yB3v1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Loading RoBERTa model*"
      ],
      "metadata": {
        "id": "Z1x87Ank4KjS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Get Model**"
      ],
      "metadata": {
        "id": "H2nUweSS-nqy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RoBERTa = 'cardiffnlp/twitter-roberta-base-sentiment'\n",
        "model = AutoModelForSequenceClassification.from_pretrained(RoBERTa)"
      ],
      "metadata": {
        "id": "Ntt_BP174jr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sparse Labels**"
      ],
      "metadata": {
        "id": "d5TEIGJE_F4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['Negative', 'Neutral', 'Positive']"
      ],
      "metadata": {
        "id": "NCfDoCaR_L0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Getting Data from Social Network (Twitter)*"
      ],
      "metadata": {
        "id": "PwUhTxIK4sUE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Search Query**"
      ],
      "metadata": {
        "id": "7VlHacE05GS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = '(from:elonmusk) until:2020-01-01 since:2010-01-01'\n",
        "limit = 3"
      ],
      "metadata": {
        "id": "V0X9Tn6n5Epd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Query Tweets and Preprocessing**"
      ],
      "metadata": {
        "id": "naBNBOMd5gRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tweets = []\n",
        "for tweet in twitter.TwitterSearchScraper(query).get_items():\n",
        "  print(vars(tweet))\n",
        "  \n",
        "  # preprocessing tweets\n",
        "  tweetWords = []\n",
        "  for word in tweet.split(' '):\n",
        "    if word.startswith('@') and len(word) > 1:\n",
        "      word = '@user'\n",
        "    elif word.startwith('http'):\n",
        "      word = 'http'\n",
        "    tweetWords.append(word)\n",
        "\n",
        "  tweetContent = ' '.join(tweetWords)\n",
        "\n",
        "  if len(tweets) == limit:\n",
        "    break\n",
        "  else:\n",
        "    tweets.append([tweet.date, tweet.username, tweetContent])\n",
        "\n",
        "dataframe = pandas.DataFrame(tweets, columns=['Date', 'User', 'Tweet'])\n",
        "print(dataframe)"
      ],
      "metadata": {
        "id": "gUnKrdSK5pWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save Tweets**"
      ],
      "metadata": {
        "id": "FPBjEFiA6Vzj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe.to_csv('tweets.csv')"
      ],
      "metadata": {
        "id": "0mIijzlw6YwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Sentiment Analysis*"
      ],
      "metadata": {
        "id": "TxIzpkzY_Tqp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tokenize Tweets**"
      ],
      "metadata": {
        "id": "JI-m2Gps_Yln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(RoBERTa)\n",
        "encodedTweet = tokenizer(tweetContent, return_tensors='pt')"
      ],
      "metadata": {
        "id": "Y70YeeMF_kVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tweet Classifications**"
      ],
      "metadata": {
        "id": "BjQ_4_8OBEPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "roBERTaBottleNeck = model(**encodedTweet)\n",
        "probabilities = softmax(roBERTaBottleNeck[0][0].detach().numpy)"
      ],
      "metadata": {
        "id": "rA7r44CxBKJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classification Table**"
      ],
      "metadata": {
        "id": "TtF1ctvGB6Mz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target = []\n",
        "for index in range(len(probabilities)):\n",
        "  if probabilities[index] > 0.4:\n",
        "    target.append([tweetContent, labels[index]])\n",
        "\n",
        "targetTable = pandas.DataFrame(target, columns=['Tweet', 'Annotation'])\n",
        "print(targetTable)"
      ],
      "metadata": {
        "id": "tBDbk7FLCB6m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}